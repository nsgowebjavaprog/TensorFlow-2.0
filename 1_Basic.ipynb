{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1de31b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " NS LONI \n"
     ]
    }
   ],
   "source": [
    "print(\" NS LONI \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c1fdf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping tensorflow as it is not installed.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f2e8844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.19.0-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\nagar\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\nagar\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\nagar\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\nagar\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\nagar\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\nagar\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\nagar\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\nagar\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\nagar\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (4.13.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\nagar\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (1.72.0rc1)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Using cached tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\nagar\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.0)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Using cached ml_dtypes-0.5.1-cp312-cp312-win_amd64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\programdata\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\nagar\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\nagar\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.5.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\nagar\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Using cached tensorflow-2.19.0-cp312-cp312-win_amd64.whl (376.0 MB)\n",
      "Using cached ml_dtypes-0.5.1-cp312-cp312-win_amd64.whl (210 kB)\n",
      "Using cached tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "Installing collected packages: ml-dtypes, tensorboard, tensorflow\n",
      "Successfully installed ml-dtypes-0.5.1 tensorboard-2.19.0 tensorflow-2.19.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script tensorboard.exe is installed in 'C:\\Users\\nagar\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts import_pb_to_tensorboard.exe, saved_model_cli.exe, tensorboard.exe, tf_upgrade_v2.exe, tflite_convert.exe and toco.exe are installed in 'C:\\Users\\nagar\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.18.0 requires ml-dtypes<0.5.0,>=0.4.0, but you have ml-dtypes 0.5.1 which is incompatible.\n",
      "tensorflow-intel 2.18.0 requires tensorboard<2.19,>=2.18, but you have tensorboard 2.19.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f7ff0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.19.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbbd08fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda6212d",
   "metadata": {},
   "source": [
    "ðŸ”¹ 1. Tensors and Tensor Operations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd41f409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constant = \n",
      " tf.Tensor(\n",
      "[[1 2 3]\n",
      " [4 5 6]], shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# tf.constant ==> im-mutable ==>  creates fixed tensors.\n",
    "\n",
    "const_tensor = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "print(\"constant = \\n\", const_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "695179a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Tensor:\n",
      " <tf.Variable 'Variable:0' shape=(2, 2) dtype=int32, numpy=\n",
      "array([[5, 6],\n",
      "       [7, 8]])>\n"
     ]
    }
   ],
   "source": [
    "# tf.Variable: mutable tensor\n",
    "var_tensor = tf.Variable([[5, 6], [7, 8]])\n",
    "print(\"Variable Tensor:\\n\", var_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee599cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "tf.Tensor(\n",
      "[[1]\n",
      " [2]], shape=(2, 1), dtype=int32)\n",
      "\n",
      "\n",
      "tf.Tensor([3 4], shape=(2,), dtype=int32)\n",
      "\n",
      "\n",
      "Broadcasted Tensor:\n",
      " tf.Tensor(\n",
      "[[4 5]\n",
      " [5 6]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Broadcasting\n",
    "a = tf.constant([[1], [2]])\n",
    "b = tf.constant([3, 4])\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(a)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(b)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "broadcasted = a + b\n",
    "print(\"Broadcasted Tensor:\\n\", broadcasted)\n",
    "\n",
    "#   [[1]   +     [3,4] ==>   [[1+3, 1+4],\n",
    "#   [2]]               ==>    [2+3, 2+4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2028c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped Tensor: tf.Tensor([4 5 5 6], shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Reshaping\n",
    "reshaped = tf.reshape(broadcasted, [4])\n",
    "print(\"Reshaped Tensor:\", reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d208abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sliced Tensor: tf.Tensor([5 6], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Slicing\n",
    "sliced = broadcasted[:, 1]\n",
    "print(\"Sliced Tensor:\", sliced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4d6542",
   "metadata": {},
   "source": [
    "ðŸ”¹ 2. Eager Execution vs Graph Execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834124c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   TensorFlow supports:\n",
    "\n",
    "#   Eager (default): operations run immediately.\n",
    "\n",
    "#   Graph: used with @tf.function for performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bb8a2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result with tf.function (Graph): tf.Tensor(16.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "@tf.function  # Compiles into graph\n",
    "def compute_square(x):\n",
    "    return x ** 2 + 2 * x + 1\n",
    "\n",
    "x = tf.constant(3.0)\n",
    "print(\"Result with tf.function (Graph):\", compute_square(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc447eb0",
   "metadata": {},
   "source": [
    "ðŸ”¹ 3. Data Pipelines using tf.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "776f0157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset from a list\n",
    "raw_data = tf.data.Dataset.from_tensor_slices([1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95ea4430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Batch: [2 8]\n",
      "Processed Batch: [ 6 10]\n",
      "Processed Batch: [4]\n"
     ]
    }
   ],
   "source": [
    "# Transformation pipeline\n",
    "processed = (\n",
    "    raw_data\n",
    "    .map(lambda x: x * 2)\n",
    "    .shuffle(buffer_size=3)\n",
    "    .batch(2)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "for batch in processed:\n",
    "    print(\"Processed Batch:\", batch.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2851258d",
   "metadata": {},
   "source": [
    "âœ… Explanation:\n",
    "\n",
    "map: transforms each element.\n",
    "\n",
    "shuffle: randomizes data.\n",
    "\n",
    "batch: groups into batches.\n",
    "\n",
    "prefetch: overlaps preprocessing and model execution â†’ boosts performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d74bc62",
   "metadata": {},
   "source": [
    "ðŸ”¹ 4. Custom Training Loops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46d6f19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained w: 2.0 b: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Simple linear model y = wx + b\n",
    "class LinearModel(tf.Module):\n",
    "    def __init__(self):\n",
    "        self.w = tf.Variable(2.0)\n",
    "        self.b = tf.Variable(1.0)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.w * x + self.b\n",
    "\n",
    "model = LinearModel()\n",
    "optimizer = tf.optimizers.SGD(learning_rate=0.01)\n",
    "x = tf.constant([1.0, 2.0, 3.0])\n",
    "y_true = tf.constant([3.0, 5.0, 7.0])  # true y = 2x + 1\n",
    "\n",
    "# Training loop\n",
    "for step in range(100):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(x)\n",
    "        loss = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "    grads = tape.gradient(loss, [model.w, model.b])\n",
    "    optimizer.apply_gradients(zip(grads, [model.w, model.b]))\n",
    "\n",
    "print(\"Trained w:\", model.w.numpy(), \"b:\", model.b.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486ffffb",
   "metadata": {},
   "source": [
    "ðŸ”¹ 5. Checkpointing and Saving Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612e2796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Keras model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1, input_shape=[1])\n",
    "])\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "\n",
    "# Save entire model\n",
    "model.save(\".\\my_model\")  # SavedModel format\n",
    "\n",
    "# Load model\n",
    "loaded_model = tf.keras.models.load_model(\"my_model\")\n",
    "print(\"Model Loaded:\", loaded_model.summary())\n",
    "\n",
    "# Using tf.train.Checkpoint\n",
    "checkpoint = tf.train.Checkpoint(model=model)\n",
    "checkpoint.save(file_prefix=\"./ckpt/model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14ecb3c",
   "metadata": {},
   "source": [
    "âœ… Explanation:\n",
    "\n",
    "model.save() saves both weights and architecture.\n",
    "\n",
    "tf.train.Checkpoint is ideal for custom training loops.\n",
    "\n",
    "Critical for resuming training, deployment, or versioning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
